{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "938b71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "#from networks import CNN_ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4682b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ARD(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.2,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.module_list = nn.ModuleList()\n",
    "\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(Conv2dARD(in_channels=channels_in,out_channels=8, kernel_size=5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(Conv2dARD(in_channels=8, out_channels=6, kernel_size=5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(Conv2dARD(in_channels=6, out_channels=4, kernel_size=2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(LinearARD(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(LinearARD(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == LinearARD or type(m) == Conv2dARD:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                try:\n",
    "                    # set bias to some small non-zero value\n",
    "                    m.bias.data.fill_(0.01)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "\n",
    "\n",
    "def get_ard_reg(module):\n",
    "    \"\"\"\n",
    "    :param module: model to evaluate ard regularization for\n",
    "    :param reg: auxilary cumulative variable for recursion\n",
    "    :return: total regularization for module\n",
    "    \"\"\"\n",
    "    if isinstance(module, LinearARD) or isinstance(module, Conv2dARD):\n",
    "        return module.get_reg()\n",
    "    elif hasattr(module, 'children'):\n",
    "        return sum([get_ard_reg(submodule) for submodule in module.children()])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _get_dropped_params_cnt(module):\n",
    "    if hasattr(module, 'get_dropped_params_cnt'):\n",
    "        return module.get_dropped_params_cnt()\n",
    "    elif hasattr(module, 'children'):\n",
    "        return sum([_get_dropped_params_cnt(submodule) for submodule in module.children()])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _get_params_cnt(module):\n",
    "    if any([isinstance(module, l) for l in [LinearARD, Conv2dARD]]):\n",
    "        return reduce(operator.mul, module.weight.shape, 1)\n",
    "    elif hasattr(module, 'children'):\n",
    "        return sum(\n",
    "            [_get_params_cnt(submodule) for submodule in module.children()])\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "\n",
    "def get_dropped_params_ratio(model):\n",
    "    return _get_dropped_params_cnt(model) * 1.0 / _get_params_cnt(model)\n",
    "\n",
    "\"\"\" LOSS FUNCTION\"\"\"\n",
    "\n",
    "class ELBOLoss(nn.Module):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super(ELBOLoss, self).__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, input, target, loss_weight=1., kl_weight=1.):\n",
    "        assert not target.requires_grad\n",
    "        # Estimate ELBO\n",
    "        return loss_weight * self.loss_fn(input, target)  \\\n",
    "            + kl_weight * get_ard_reg(self.net)\n",
    "\n",
    "\n",
    "\"\"\" FULLY CONNECTED LAYER\"\"\"\n",
    "class LinearARD(nn.Module):\n",
    "    \"\"\"\n",
    "    Dense layer implementation with weights ARD-prior (arxiv:1701.05369)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, thresh=3, ard_init=-10):\n",
    "        super(LinearARD, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.thresh = thresh\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.ard_init = ard_init\n",
    "        self.log_sigma2 = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.log_sigma2_bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            W_mu = F.linear(input, self.weight)\n",
    "            std_w = torch.exp(self.log_alpha).permute(1,0)\n",
    "            W_std = torch.sqrt((input.pow(2)).matmul(std_w*(self.weight.permute(1,0)**2)) + 1e-15)\n",
    "\n",
    "            epsilon = W_std.new(W_std.shape).normal_()\n",
    "            output = W_mu + W_std * epsilon\n",
    "            if self.bias is not None: \n",
    "              output += self.bias\n",
    "        else:\n",
    "            W = self.weights_clipped\n",
    "            output = F.linear(input, W) + self.bias\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def weights_clipped(self):\n",
    "        clip_mask = self.get_clip_mask()\n",
    "        return torch.where(clip_mask, torch.zeros_like(self.weight), self.weight)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.normal_(0, 0.02)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "        self.log_sigma2.data.fill_(self.ard_init)\n",
    "\n",
    "    def get_clip_mask(self):\n",
    "        log_alpha = self.log_alpha\n",
    "        return torch.ge(log_alpha, self.thresh)\n",
    "\n",
    "    def get_reg(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Get weights regularization (KL(q(w)||p(w)) approximation)\n",
    "        \"\"\"\n",
    "        k1, k2, k3 = 0.63576, 1.8732, 1.48695\n",
    "        C = -k1\n",
    "        mdkl = k1 * torch.sigmoid(k2 + k3 * self.log_alpha) - \\\n",
    "            0.5 * torch.log1p(torch.exp(-self.log_alpha)) + C\n",
    "        return -torch.sum(mdkl)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "    def get_dropped_params_cnt(self):\n",
    "        \"\"\"\n",
    "        Get number of dropped weights (with log alpha greater than \"thresh\" parameter)\n",
    "        :returns (number of dropped weights, number of all weight)\n",
    "        \"\"\"\n",
    "        return self.get_clip_mask().sum().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def log_alpha(self):\n",
    "        log_alpha = self.log_sigma2 - 2 * \\\n",
    "            torch.log(torch.abs(self.weight) + 1e-15)\n",
    "        return torch.clamp(log_alpha, -10, 10)\n",
    "\n",
    "\n",
    "\"\"\" CONVOLUTIONAL LAYER \"\"\"\n",
    "\n",
    "class Conv2dARD(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, ard_init=-10, thresh=3,bias=True):\n",
    "        # bias = False  # Goes to nan if bias = True\n",
    "        super(Conv2dARD, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                        padding, dilation, groups, bias)\n",
    "        # self.bias = None\n",
    "        self.thresh = thresh\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ard_init = ard_init\n",
    "        self.log_sigma2 = nn.Parameter(ard_init * torch.ones_like(self.weight))\n",
    "        self.log_sigma2_bias = nn.Parameter(ard_init * torch.ones_like(self.bias))\n",
    "        # self.log_sigma2 = Parameter(2 * torch.log(torch.abs(self.weight) + eps).clone().detach()+ard_init*torch.ones_like(self.weight))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward with all regularized connections and random activations (Beyesian mode). Typically used for train\n",
    "        \"\"\"\n",
    "        if self.training == False:\n",
    "            weights_clipped = self.weights_clipped\n",
    "            # bias_clipped = self.bias_clipped()\n",
    "            bias_clipped = self.bias_clipped()\n",
    "            return F.conv2d(input, weights_clipped,\n",
    "                            bias_clipped, self.stride,\n",
    "                            self.padding, self.dilation, self.groups)\n",
    "            # return F.conv2d(input, self.weights_clipped,\n",
    "            #                 self.bias, self.stride,\n",
    "            #                 self.padding, self.dilation, self.groups)\n",
    "        W = self.weight\n",
    "        b = self.bias\n",
    "        conved_mu = F.conv2d(input, W, self.bias, self.stride,\n",
    "                             self.padding, self.dilation, self.groups)\n",
    "        log_alpha = self.log_alpha\n",
    "        log_alpha_bias = self.log_alpha_bias()\n",
    "        conved_si = torch.sqrt(1e-15 + F.conv2d(input * input,\n",
    "                                                torch.exp(log_alpha) * W *\n",
    "                                                W, torch.exp(log_alpha_bias)*b*b, self.stride,\n",
    "                                                self.padding, self.dilation, self.groups))\n",
    "        \n",
    "        # conved_si = torch.sqrt(1e-15 + F.conv2d(input * input,\n",
    "        #                                         torch.exp(log_alpha) * W *\n",
    "        #                                         W, self.bias, self.stride,\n",
    "        #                                         self.padding, self.dilation, self.groups))\n",
    "        conved = conved_mu + \\\n",
    "            conved_si * \\\n",
    "            torch.normal(torch.zeros_like(conved_mu),\n",
    "                         torch.ones_like(conved_mu))\n",
    "        return conved\n",
    "\n",
    "    @property\n",
    "    def weights_clipped(self):\n",
    "        clip_mask = self.get_clip_mask()\n",
    "        return torch.where(clip_mask, torch.zeros_like(self.weight), self.weight)\n",
    "    \n",
    "    def get_clip_mask(self):\n",
    "        log_alpha = self.log_alpha\n",
    "        return torch.ge(log_alpha, self.thresh)\n",
    "    \n",
    "    # @property\n",
    "    def bias_clipped(self):\n",
    "        clip_mask = self.get_clip_mask_bias()\n",
    "        return torch.where(clip_mask, torch.zeros_like(self.bias), self.bias)\n",
    "\n",
    "    def get_clip_mask_bias(self):\n",
    "        log_alpha_bias = self.log_alpha_bias()\n",
    "        return torch.ge(log_alpha_bias, self.thresh)\n",
    "\n",
    "    def get_reg(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Get weights regularization (KL(q(w)||p(w)) approximation)\n",
    "        \"\"\"\n",
    "        k1, k2, k3 = 0.63576, 1.8732, 1.48695\n",
    "        C = -k1\n",
    "        log_alpha = self.log_alpha\n",
    "        mdkl = k1 * torch.sigmoid(k2 + k3 * log_alpha) - \\\n",
    "            0.5 * torch.log1p(torch.exp(-log_alpha)) + C\n",
    "        # add bias\n",
    "        log_alpha_bias = self.log_alpha_bias()\n",
    "        mdkl_b = k1 * torch.sigmoid(k2 + k3 * log_alpha_bias) - \\\n",
    "            0.5 * torch.log1p(torch.exp(-log_alpha_bias)) + C\n",
    "        return -torch.sum(mdkl) - torch.sum(mdkl_b)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_channels, self.out_channels, self.bias is not None\n",
    "        )\n",
    "\n",
    "    def get_dropped_params_cnt(self):\n",
    "        \"\"\"\n",
    "        Get number of dropped weights (greater than \"thresh\" parameter)\n",
    "        :returns (number of dropped weights, number of all weight)\n",
    "        \"\"\"\n",
    "        return self.get_clip_mask().sum().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def log_alpha(self):\n",
    "        log_alpha = self.log_sigma2 - 2 * \\\n",
    "            torch.log(torch.abs(self.weight) + 1e-15)\n",
    "        return torch.clamp(log_alpha, -8, 8)\n",
    "    \n",
    "    # @property\n",
    "    def log_alpha_bias(self):\n",
    "        log_alpha_bias = self.log_sigma2_bias - 2 * \\\n",
    "            torch.log(torch.abs(self.bias) + 1e-15)\n",
    "        return torch.clamp(log_alpha_bias, -8, 8)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# define net\n",
    "# ##############################################################################\n",
    "def compute_outdim(i_dim, stride, kernel, padding, dilation):\n",
    "    o_dim = (i_dim + 2 * padding - dilation * (kernel - 1) - 1) / stride + 1\n",
    "    return o_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_names_for_path(dataset, setup):\n",
    "    if dataset==\"CIFAR10\":\n",
    "        size = \"large\"\n",
    "    else:\n",
    "        size = \"small\"\n",
    "    \n",
    "    if setup == \"seed\":\n",
    "        zoo_p = f\"cnn_{size}_{dataset.lower()}_ard\"\n",
    "    elif setup == \"hyp-10-f\":\n",
    "        zoo_p = f\"cnn_{size}_{dataset.lower()}_fixed_ard\"\n",
    "    else: \n",
    "        zoo_p = f\"cnn_{size}_{dataset.lower()}_rand_ard\"\n",
    "\n",
    "    return zoo_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f45e0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"dataset\"] = \"MNIST\"\n",
    "config[\"setup\"] = \"hyp-10-f\"\n",
    "ROOT = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "066ea925",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_p = return_names_for_path(config[\"dataset\"], config[\"setup\"])\n",
    "checkpoint_path = os.path.join(ROOT, f\"/ds2/model_zoos/zoos_sparsified/distillation/zoos/{config['dataset']}/ARD/{zoo_p}\")\n",
    "# path to \"dataset\"\n",
    "data_path = os.path.join(checkpoint_path, \"dataset.pt\")  \n",
    "data_root = os.path.join(ROOT, \"/netscratch2/jlautz/model_robustness/src/model_robustness/data/sparsified\")\n",
    "\n",
    "# Defining path on where to store the 50 models used to generate perturbed dataset\n",
    "model_list_path = Path(\n",
    "    os.path.join(data_root, config[\"dataset\"], \"PGD\"))\n",
    "\n",
    "with open(os.path.join(model_list_path, 'model_list.txt'), \"r\") as items:\n",
    "    model_paths = items.readlines()\n",
    "\n",
    "    for i, l in enumerate(model_paths):\n",
    "        model_paths[i] = l.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d71cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "dataset = torch.load(data_path)[\"testset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b631536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f6dffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subsets of testset used for each of the n_models models\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "imgs_per_model = len(dataset) / 50\n",
    "split = [int(imgs_per_model) for i in range(50)]\n",
    "remainder = len(dataset) - sum(split)\n",
    "split[-1] += remainder\n",
    "\n",
    "subsets = random_split(dataset, split, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18b022b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = []\n",
    "for path in os.listdir(checkpoint_path):\n",
    "    if not os.path.isfile(os.path.join(checkpoint_path, path)):\n",
    "        a+=1\n",
    "        if not os.path.exists(os.path.join(checkpoint_path, path, \"checkpoint_000025\", \"checkpoints\")):\n",
    "            b.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ef751f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3607 1114\n"
     ]
    }
   ],
   "source": [
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67801d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3088439146104796"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
