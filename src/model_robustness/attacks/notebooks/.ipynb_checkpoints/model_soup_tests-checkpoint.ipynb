{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d5c469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from model_robustness.attacks.networks import ResNet18, ConvNetLarge\n",
    "\n",
    "ROOT = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef55e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(ROOT, \"/ds2/model_zoos/zoos_v2/CIFAR10/large/tune_zoo_cifar10_large_hyperparameter_10_fixed_seeds/dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1068e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785a3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trainset', 'valset', 'testset', 'dataset_seed'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8660651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[\"valset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd70bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"/ds2/model_zoos/zoos_v2/CIFAR10/large/tune_zoo_cifar10_large_hyperparameter_10_fixed_seeds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d27f8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = []\n",
    "for path in os.listdir(result_path):\n",
    "    if not os.path.isfile(os.path.join(result_path, path)):\n",
    "        if path.startswith(\"NN\"):\n",
    "                model_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7840b254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbd155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train_loss\": 0.709677963291428, \"train_acc\": 0.7509047619047619, \"validation_loss\": 0.9630947709083557, \"validation_acc\": 0.67525, \"test_loss\": 0.9473087787628174, \"test_acc\": 0.6771, \"done\": false, \"timesteps_total\": null, \"episodes_total\": null, \"training_iteration\": 49, \"experiment_id\": \"0074244a158f49a4810ca24126c1a91a\", \"date\": \"2021-09-23_18-55-42\", \"timestamp\": 1632423342, \"time_this_iter_s\": 44.526055097579956, \"time_total_s\": 2136.8347334861755, \"pid\": 24167, \"hostname\": \"855f4f36dc70\", \"node_ip\": \"172.17.0.17\", \"config\": {\"model::type\": \"CNN3\", \"model::channels_in\": 3, \"model::o_dim\": 10, \"model::nlin\": \"gelu\", \"model::dropout\": 0, \"model::init_type\": \"kaiming_normal\", \"model::use_bias\": false, \"optim::optimizer\": \"sgd\", \"optim::lr\": 0.001, \"optim::wd\": 0.001, \"optim::momentum\": 0.9, \"seed\": 5, \"training::batchsize\": 10, \"training::epochs_train\": 50, \"training::start_epoch\": 1, \"training::output_epoch\": 1, \"training::val_epochs\": 1, \"training::idx_out\": 500, \"training::checkpoint_dir\": null, \"cuda\": false, \"dataset::dump\": \"/netscratch/dtaskiran/zoos/CIFAR10/large/tune_zoo_cifar10_large_hyperparameter_10_fixed_seeds/dataset.pt\", \"wandb\": {\"project\": \"Corr: CIFAR Fixed Seed Large\", \"api_key_file\": \"/netscratch/dtaskiran/wandb/wandb.key\", \"log_config\": false}}, \"time_since_restore\": 2136.8347334861755, \"timesteps_since_restore\": 0, \"iterations_since_restore\": 50, \"trial_id\": \"143c9_00638\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(model_paths):\n",
    "    result_model_path = os.path.join(result_path, path, \"result.json\")\n",
    "    \n",
    "    c = 0\n",
    "    for line in open(result_model_path, \"r\"):\n",
    "        c +=1 \n",
    "        if c == 50:\n",
    "            print(line)\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d29b84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for k, v in uniform_soup.items():\n",
    "    break\n",
    "    if torch.isnan(v).any():\n",
    "        a.append[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01873dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4a617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "010ad0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 14/1280 contains NaNs and is skipped\n",
      "Model 32/1280 contains NaNs and is skipped\n",
      "Model 78/1280 contains NaNs and is skipped\n",
      "Model 110/1280 contains NaNs and is skipped\n",
      "Model 126/1280 contains NaNs and is skipped\n",
      "Model 142/1280 contains NaNs and is skipped\n",
      "Model 176/1280 contains NaNs and is skipped\n",
      "Model 177/1280 contains NaNs and is skipped\n",
      "Model 187/1280 contains NaNs and is skipped\n",
      "Model 191/1280 contains NaNs and is skipped\n",
      "Model 199/1280 contains NaNs and is skipped\n",
      "Model 211/1280 contains NaNs and is skipped\n",
      "Model 226/1280 contains NaNs and is skipped\n",
      "Model 234/1280 contains NaNs and is skipped\n",
      "Model 241/1280 contains NaNs and is skipped\n",
      "Model 272/1280 contains NaNs and is skipped\n",
      "Model 304/1280 contains NaNs and is skipped\n",
      "Model 320/1280 contains NaNs and is skipped\n",
      "Model 325/1280 contains NaNs and is skipped\n",
      "Model 339/1280 contains NaNs and is skipped\n",
      "Model 340/1280 contains NaNs and is skipped\n",
      "Model 341/1280 contains NaNs and is skipped\n",
      "Model 345/1280 contains NaNs and is skipped\n",
      "Model 363/1280 contains NaNs and is skipped\n",
      "Model 407/1280 contains NaNs and is skipped\n",
      "Model 447/1280 contains NaNs and is skipped\n",
      "Model 454/1280 contains NaNs and is skipped\n",
      "Model 460/1280 contains NaNs and is skipped\n",
      "Model 488/1280 contains NaNs and is skipped\n",
      "Model 490/1280 contains NaNs and is skipped\n",
      "Model 557/1280 contains NaNs and is skipped\n",
      "Model 572/1280 contains NaNs and is skipped\n",
      "Model 582/1280 contains NaNs and is skipped\n",
      "Model 614/1280 contains NaNs and is skipped\n",
      "Model 617/1280 contains NaNs and is skipped\n",
      "Model 633/1280 contains NaNs and is skipped\n",
      "Model 638/1280 contains NaNs and is skipped\n",
      "Model 646/1280 contains NaNs and is skipped\n",
      "Model 654/1280 contains NaNs and is skipped\n",
      "Model 696/1280 contains NaNs and is skipped\n",
      "Model 714/1280 contains NaNs and is skipped\n",
      "Model 777/1280 contains NaNs and is skipped\n",
      "Model 781/1280 contains NaNs and is skipped\n",
      "Model 805/1280 contains NaNs and is skipped\n",
      "Model 874/1280 contains NaNs and is skipped\n",
      "Model 876/1280 contains NaNs and is skipped\n",
      "Model 880/1280 contains NaNs and is skipped\n",
      "Model 896/1280 contains NaNs and is skipped\n",
      "Model 924/1280 contains NaNs and is skipped\n",
      "Model 958/1280 contains NaNs and is skipped\n",
      "Model 961/1280 contains NaNs and is skipped\n",
      "Model 984/1280 contains NaNs and is skipped\n",
      "Model 993/1280 contains NaNs and is skipped\n",
      "Model 994/1280 contains NaNs and is skipped\n",
      "Model 996/1280 contains NaNs and is skipped\n",
      "Model 1023/1280 contains NaNs and is skipped\n",
      "Model 1024/1280 contains NaNs and is skipped\n",
      "Model 1055/1280 contains NaNs and is skipped\n",
      "Model 1064/1280 contains NaNs and is skipped\n",
      "Model 1075/1280 contains NaNs and is skipped\n",
      "Model 1079/1280 contains NaNs and is skipped\n",
      "Model 1123/1280 contains NaNs and is skipped\n",
      "Model 1147/1280 contains NaNs and is skipped\n",
      "Model 1148/1280 contains NaNs and is skipped\n",
      "Model 1164/1280 contains NaNs and is skipped\n",
      "Model 1167/1280 contains NaNs and is skipped\n",
      "Model 1256/1280 contains NaNs and is skipped\n",
      "Model 1279/1280 contains NaNs and is skipped\n",
      "Uniform soup contains 1212/1280 models.\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "aux = False\n",
    "for i, path in enumerate(model_paths):\n",
    "    result_model_path = os.path.join(result_path, path, \"checkpoint_000050\", \"checkpoints\")\n",
    "    \n",
    "    assert os.path.exists(result_model_path)\n",
    "    \n",
    "    state_dict = torch.load(result_model_path)\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if aux:\n",
    "            continue \n",
    "        if torch.isnan(value).any():\n",
    "            a += 1\n",
    "            print(f\"Model {i+1}/{len(model_paths)} contains NaNs and is skipped\")\n",
    "            \n",
    "            aux = True\n",
    "\n",
    "    if aux:\n",
    "        pass\n",
    "    else:\n",
    "        if i == 0:    \n",
    "            uniform_soup = {k: v * (1./len(model_paths)) for k, v in state_dict.items()}\n",
    "        else:\n",
    "            uniform_soup = {k: v * (1./len(model_paths)) + uniform_soup[k] for k, v in state_dict.items()}\n",
    "    aux = False\n",
    "print(f\"Uniform soup contains {len(model_paths) - a}/{len(model_paths)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ada217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniform_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73a5e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration of best model\n",
    "zoo_path = os.path.join(ROOT, \"/ds2/model_zoos/zoos_v2/CIFAR10/large/analysis_data_hyp_fix.pt\")\n",
    "zoo = torch.load(zoo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3315ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "index_list = [50]\n",
    "path_list = []\n",
    "for i in range(len(zoo[\"paths\"])):\n",
    "    if i == 0:\n",
    "        aux = zoo[\"paths\"][i]\n",
    "        path_list.append(zoo[\"paths\"][i])\n",
    "\n",
    "    if zoo[\"paths\"][i] == aux:\n",
    "        pass\n",
    "    else:\n",
    "        a += 1\n",
    "        index_list.append(i+50)\n",
    "        aux = zoo[\"paths\"][i]\n",
    "        path_list.append(aux)\n",
    "\n",
    "for i in range(len(path_list)):\n",
    "    path_list[i] = path_list[i].__str__().split(\"/\")[-1]\n",
    "\n",
    "# Get all accuracies\n",
    "acc_list = []\n",
    "for index in index_list:\n",
    "    acc_list.append(zoo[\"acc\"][index])\n",
    "\n",
    "# Get the index of max element\n",
    "max_index = acc_list.index(max(acc_list))\n",
    "\n",
    "# Get the corresponding model name\n",
    "best_model_path = path_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c9942430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, model, config_model):\n",
    "\n",
    "    # Define dataloader for evaluation\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config_model[\"training::batchsize\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Define criterion and optimizer\n",
    "    if config_model[\"optim::optimizer\"] == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config_model[\"optim::lr\"], \n",
    "            momentum=config_model[\"optim::momentum\"], weight_decay=config_model[\"optim::wd\"])\n",
    "\n",
    "    elif config_model[\"optim::optimizer\"] == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config_model[\"optim::lr\"], \n",
    "            weight_decay=config_model[\"optim::wd\"])\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Evaluate        \n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "\n",
    "    for j, data in enumerate(loader):\n",
    "                \n",
    "        model.eval()\n",
    "\n",
    "        imgs, labels = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        n_b = labels.shape[0]\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        acc = np.sum(np.equal(np.argmax(outputs.cpu().data.numpy(), axis=-1),\n",
    "            labels.cpu().data.numpy()))\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "        if j % 250 == 0:\n",
    "            print(f\"Batch {j} of {len(dataset)/config_model['training::batchsize']} done.\")\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30b7e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 1000.0 done.\n",
      "Batch 250 of 1000.0 done.\n",
      "Batch 500 of 1000.0 done.\n",
      "Batch 750 of 1000.0 done.\n",
      "Soup: Loss = 0.08775529526546598, Accuracy = 0.7023\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvNetLarge:\n\tMissing key(s) in state_dict: \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.6.weight\", \"module_list.6.bias\", \"module_list.10.weight\", \"module_list.10.bias\", \"module_list.12.weight\", \"module_list.12.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.13.weight\", \"module_list.13.bias\", \"module_list.16.weight\", \"module_list.16.bias\", \"module_list.4.weight\", \"module_list.4.bias\", \"module_list.8.weight\", \"module_list.8.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m ConvNetLarge(\n\u001b[1;32m     23\u001b[0m         channels_in\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::channels_in\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     24\u001b[0m         nlin\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::nlin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::dropout\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m         init_type\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::init_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniform_soup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m evaluate(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestset\u001b[39m\u001b[38;5;124m\"\u001b[39m], model, config_model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNetLarge:\n\tMissing key(s) in state_dict: \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.6.weight\", \"module_list.6.bias\", \"module_list.10.weight\", \"module_list.10.bias\", \"module_list.12.weight\", \"module_list.12.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.13.weight\", \"module_list.13.bias\", \"module_list.16.weight\", \"module_list.16.bias\", \"module_list.4.weight\", \"module_list.4.bias\", \"module_list.8.weight\", \"module_list.8.bias\". "
     ]
    }
   ],
   "source": [
    "model_config_path = os.path.join(ROOT, result_path, best_model_path, \"params.json\")\n",
    "config_model = json.load(open(model_config_path, ))\n",
    "device = \"cpu\"\n",
    "\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        model = ConvNetLarge(\n",
    "            channels_in=config_model[\"model::channels_in\"],\n",
    "            nlin=config_model[\"model::nlin\"],\n",
    "            dropout=0.5,\n",
    "            init_type=config_model[\"model::init_type\"]\n",
    "        )\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(ROOT, result_path, best_model_path, \"checkpoint_000050\", \"checkpoints\"), map_location=torch.device(device))\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "        print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")\n",
    "    \n",
    "    else:\n",
    "        model = ConvNetLarge(\n",
    "            channels_in=config_model[\"model::channels_in\"],\n",
    "            nlin=config_model[\"model::nlin\"],\n",
    "            dropout=0.5,\n",
    "            init_type=config_model[\"model::init_type\"]\n",
    "        )\n",
    "        model.load_state_dict(uniform_soup)\n",
    "        model.to(device)\n",
    "        \n",
    "        loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "        print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "213df274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/all_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cda9db28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN_tune_trainable_143c9_00090_90_model::dropout=0,model::init_type=normal,model::nlin=gelu,optim::optimizer=adam,optim::wd=0.001,s_2021-09-22_14-12-28'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44b2a63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>attack</th>\n",
       "      <th>setup</th>\n",
       "      <th>eps</th>\n",
       "      <th>dropout</th>\n",
       "      <th>init_type</th>\n",
       "      <th>nlin</th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>seed</th>\n",
       "      <th>old_loss</th>\n",
       "      <th>old_acc</th>\n",
       "      <th>new_loss</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64281</th>\n",
       "      <td>64281</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.227410</td>\n",
       "      <td>0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65525</th>\n",
       "      <td>65525</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.250552</td>\n",
       "      <td>0.2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67056</th>\n",
       "      <td>67056</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.279157</td>\n",
       "      <td>0.2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69042</th>\n",
       "      <td>69042</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.307301</td>\n",
       "      <td>0.1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69195</th>\n",
       "      <td>69195</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.334626</td>\n",
       "      <td>0.1755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71222</th>\n",
       "      <td>71222</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.233477</td>\n",
       "      <td>0.2602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71969</th>\n",
       "      <td>71969</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.258924</td>\n",
       "      <td>0.2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73110</th>\n",
       "      <td>73110</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.276467</td>\n",
       "      <td>0.2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74807</th>\n",
       "      <td>74807</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.291618</td>\n",
       "      <td>0.1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76406</th>\n",
       "      <td>76406</td>\n",
       "      <td>NN_tune_trainable_143c9_00090_90_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.304804</td>\n",
       "      <td>0.1825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               name  dataset  \\\n",
       "64281       64281  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "65525       65525  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "67056       67056  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "69042       69042  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "69195       69195  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "71222       71222  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "71969       71969  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "73110       73110  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "74807       74807  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "76406       76406  NN_tune_trainable_143c9_00090_90_model::dropou...  CIFAR10   \n",
       "\n",
       "      attack     setup  eps  dropout init_type  nlin     lr  momentum  \\\n",
       "64281    PGD  hyp-10-f  0.1      0.0    normal  gelu  0.001       0.9   \n",
       "65525    PGD  hyp-10-f  0.2      0.0    normal  gelu  0.001       0.9   \n",
       "67056    PGD  hyp-10-f  0.3      0.0    normal  gelu  0.001       0.9   \n",
       "69042    PGD  hyp-10-f  0.4      0.0    normal  gelu  0.001       0.9   \n",
       "69195    PGD  hyp-10-f  0.5      0.0    normal  gelu  0.001       0.9   \n",
       "71222   FGSM  hyp-10-f  0.1      0.0    normal  gelu  0.001       0.9   \n",
       "71969   FGSM  hyp-10-f  0.2      0.0    normal  gelu  0.001       0.9   \n",
       "73110   FGSM  hyp-10-f  0.3      0.0    normal  gelu  0.001       0.9   \n",
       "74807   FGSM  hyp-10-f  0.4      0.0    normal  gelu  0.001       0.9   \n",
       "76406   FGSM  hyp-10-f  0.5      0.0    normal  gelu  0.001       0.9   \n",
       "\n",
       "      optimizer     wd  seed  old_loss  old_acc  new_loss  new_acc  \n",
       "64281      adam  0.001     1     0.887    0.699  0.227410   0.2836  \n",
       "65525      adam  0.001     1     0.887    0.699  0.250552   0.2441  \n",
       "67056      adam  0.001     1     0.887    0.699  0.279157   0.2111  \n",
       "69042      adam  0.001     1     0.887    0.699  0.307301   0.1897  \n",
       "69195      adam  0.001     1     0.887    0.699  0.334626   0.1755  \n",
       "71222      adam  0.001     1     0.887    0.699  0.233477   0.2602  \n",
       "71969      adam  0.001     1     0.887    0.699  0.258924   0.2181  \n",
       "73110      adam  0.001     1     0.887    0.699  0.276467   0.2007  \n",
       "74807      adam  0.001     1     0.887    0.699  0.291618   0.1878  \n",
       "76406      adam  0.001     1     0.887    0.699  0.304804   0.1825  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.name==best_model_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0563ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2145ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 1000.0 done.\n",
      "Batch 250 of 1000.0 done.\n",
      "Batch 500 of 1000.0 done.\n",
      "Batch 750 of 1000.0 done.\n",
      "Soup: Loss = nan, Accuracy = 0.1\n"
     ]
    }
   ],
   "source": [
    "model_config_path = os.path.join(ROOT, result_path, best_model_path, \"params.json\")\n",
    "config_model = json.load(open(model_config_path, ))\n",
    "device = \"cpu\"\n",
    "\n",
    "model = ConvNetLarge(\n",
    "    channels_in=config_model[\"model::channels_in\"],\n",
    "    nlin=config_model[\"model::nlin\"],\n",
    "    dropout=0.5,\n",
    "    init_type=config_model[\"model::init_type\"]\n",
    ")\n",
    "model.load_state_dict(uniform_soup)\n",
    "model.to(device)\n",
    "\n",
    "loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f92bf026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.8777e+09, -5.8940e+09, -5.2654e+09],\n",
       "        [-6.0085e+09, -4.4389e+09, -3.4949e+09],\n",
       "        [-3.7270e+09, -2.7898e+09, -1.7723e+09]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_soup[\"module_list.0.weight\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "62f63022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0145, -0.3294,  0.2620],\n",
       "        [-0.3636,  0.1903,  0.3682],\n",
       "        [ 0.1038,  0.3367, -0.3192]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(os.path.join(ROOT, result_path, best_model_path, \"checkpoint_000050\", \"checkpoints\"), map_location=torch.device(device))[\"module_list.0.weight\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c52b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
