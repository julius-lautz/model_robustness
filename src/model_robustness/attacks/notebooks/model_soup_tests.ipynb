{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "94200261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from model_robustness.attacks.networks import ResNet18, ConvNetLarge, ConvNetSmall\n",
    "\n",
    "ROOT = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "29cff284",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(ROOT, \"/ds2/model_zoos/zoos_v2/MNIST/tune_zoo_mnist_hyperparameter_10_fixed_seeds/dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0ea5a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "94d5a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"/ds2/model_zoos/zoos_v2/MNIST/tune_zoo_mnist_hyperparameter_10_fixed_seeds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "52eab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = []\n",
    "for path in os.listdir(result_path):\n",
    "    if not os.path.isfile(os.path.join(result_path, path)):\n",
    "        if path.startswith(\"NN\"):\n",
    "                model_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "08c93f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da410461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train_loss\": 0.709677963291428, \"train_acc\": 0.7509047619047619, \"validation_loss\": 0.9630947709083557, \"validation_acc\": 0.67525, \"test_loss\": 0.9473087787628174, \"test_acc\": 0.6771, \"done\": false, \"timesteps_total\": null, \"episodes_total\": null, \"training_iteration\": 49, \"experiment_id\": \"0074244a158f49a4810ca24126c1a91a\", \"date\": \"2021-09-23_18-55-42\", \"timestamp\": 1632423342, \"time_this_iter_s\": 44.526055097579956, \"time_total_s\": 2136.8347334861755, \"pid\": 24167, \"hostname\": \"855f4f36dc70\", \"node_ip\": \"172.17.0.17\", \"config\": {\"model::type\": \"CNN3\", \"model::channels_in\": 3, \"model::o_dim\": 10, \"model::nlin\": \"gelu\", \"model::dropout\": 0, \"model::init_type\": \"kaiming_normal\", \"model::use_bias\": false, \"optim::optimizer\": \"sgd\", \"optim::lr\": 0.001, \"optim::wd\": 0.001, \"optim::momentum\": 0.9, \"seed\": 5, \"training::batchsize\": 10, \"training::epochs_train\": 50, \"training::start_epoch\": 1, \"training::output_epoch\": 1, \"training::val_epochs\": 1, \"training::idx_out\": 500, \"training::checkpoint_dir\": null, \"cuda\": false, \"dataset::dump\": \"/netscratch/dtaskiran/zoos/CIFAR10/large/tune_zoo_cifar10_large_hyperparameter_10_fixed_seeds/dataset.pt\", \"wandb\": {\"project\": \"Corr: CIFAR Fixed Seed Large\", \"api_key_file\": \"/netscratch/dtaskiran/wandb/wandb.key\", \"log_config\": false}}, \"time_since_restore\": 2136.8347334861755, \"timesteps_since_restore\": 0, \"iterations_since_restore\": 50, \"trial_id\": \"143c9_00638\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(model_paths):\n",
    "    result_model_path = os.path.join(result_path, path, \"result.json\")\n",
    "    \n",
    "    c = 0\n",
    "    for line in open(result_model_path, \"r\"):\n",
    "        c +=1 \n",
    "        if c == 50:\n",
    "            print(line)\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4aad5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uniform_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43muniform_soup\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(v)\u001b[38;5;241m.\u001b[39many():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uniform_soup' is not defined"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for k, v in uniform_soup.items():\n",
    "    break\n",
    "    if torch.isnan(v).any():\n",
    "        a.append[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47386ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098a093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a37ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load(os.path.join(result_path, model_paths[67], \"checkpoint_000050\", \"checkpoints\"))\n",
    "\n",
    "for key,val in test.items():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91662c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0054,  0.0348, -1.7791,  0.0300,  0.1887,  0.0958, -0.0161,  0.3170,\n",
       "         0.7117,  0.4241])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ee076f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"gradients\"])\n",
    "for i, path in enumerate(model_paths):\n",
    "    checkpoints = []\n",
    "    for p in os.listdir(os.path.join(result_path, path)):\n",
    "        if p.startswith(\"checkpoint\"):\n",
    "            checkpoints.append(p)\n",
    "    checkpoints.sort()\n",
    "    result_model_path = os.path.join(result_path, path, \"checkpoint_000050\", \"checkpoints\")\n",
    "    state_dict = torch.load(result_model_path)\n",
    "    df.loc[i, \"gradients\"] = state_dict[\"module_list.0.weight\"][0][0][0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70652373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradients    6431803.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d08c62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/all_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "af48d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.dataset==\"MNIST\"]\n",
    "df = df[df.setup==\"hyp-10-f\"]\n",
    "df = df[df.attack==\"PGD\"]\n",
    "df = df[df.eps==0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fda546a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "40264694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take seed = 1, init_type=kaiming_uniform, nlin=tanh\n",
    "df = df[(df.seed==1) & (df.init_type==\"uniform\") & (df.nlin==\"tanh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2f5d83fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>attack</th>\n",
       "      <th>setup</th>\n",
       "      <th>eps</th>\n",
       "      <th>dropout</th>\n",
       "      <th>init_type</th>\n",
       "      <th>nlin</th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>seed</th>\n",
       "      <th>old_loss</th>\n",
       "      <th>old_acc</th>\n",
       "      <th>new_loss</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38557</th>\n",
       "      <td>38557</td>\n",
       "      <td>NN_tune_trainable_b6a12_00161_161_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.099562</td>\n",
       "      <td>0.6483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38768</th>\n",
       "      <td>38768</td>\n",
       "      <td>NN_tune_trainable_b6a12_00160_160_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.108685</td>\n",
       "      <td>0.6873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38835</th>\n",
       "      <td>38835</td>\n",
       "      <td>NN_tune_trainable_b6a12_00129_129_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.505041</td>\n",
       "      <td>0.1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38848</th>\n",
       "      <td>38848</td>\n",
       "      <td>NN_tune_trainable_b6a12_00193_193_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.210894</td>\n",
       "      <td>0.4070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39431</th>\n",
       "      <td>39431</td>\n",
       "      <td>NN_tune_trainable_b6a12_00064_64_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.279926</td>\n",
       "      <td>0.3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39858</th>\n",
       "      <td>39858</td>\n",
       "      <td>NN_tune_trainable_b6a12_00096_96_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.301</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.230131</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39873</th>\n",
       "      <td>39873</td>\n",
       "      <td>NN_tune_trainable_b6a12_00128_128_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.179025</td>\n",
       "      <td>0.5630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39884</th>\n",
       "      <td>39884</td>\n",
       "      <td>NN_tune_trainable_b6a12_00224_224_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.301</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.230131</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>40002</td>\n",
       "      <td>NN_tune_trainable_b6a12_00192_192_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.303</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.230614</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40215</th>\n",
       "      <td>40215</td>\n",
       "      <td>NN_tune_trainable_b6a12_00097_97_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.278</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40224</th>\n",
       "      <td>40224</td>\n",
       "      <td>NN_tune_trainable_b6a12_00000_0_model::dropout...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>0.5193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40314</th>\n",
       "      <td>40314</td>\n",
       "      <td>NN_tune_trainable_b6a12_00065_65_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.486701</td>\n",
       "      <td>0.1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40418</th>\n",
       "      <td>40418</td>\n",
       "      <td>NN_tune_trainable_b6a12_00225_225_model::dropo...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.293</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.230215</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40602</th>\n",
       "      <td>40602</td>\n",
       "      <td>NN_tune_trainable_b6a12_00032_32_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.340227</td>\n",
       "      <td>0.3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40642</th>\n",
       "      <td>40642</td>\n",
       "      <td>NN_tune_trainable_b6a12_00033_33_model::dropou...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.146339</td>\n",
       "      <td>0.5740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40698</th>\n",
       "      <td>40698</td>\n",
       "      <td>NN_tune_trainable_b6a12_00001_1_model::dropout...</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.458088</td>\n",
       "      <td>0.1135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               name dataset  \\\n",
       "38557       38557  NN_tune_trainable_b6a12_00161_161_model::dropo...   MNIST   \n",
       "38768       38768  NN_tune_trainable_b6a12_00160_160_model::dropo...   MNIST   \n",
       "38835       38835  NN_tune_trainable_b6a12_00129_129_model::dropo...   MNIST   \n",
       "38848       38848  NN_tune_trainable_b6a12_00193_193_model::dropo...   MNIST   \n",
       "39431       39431  NN_tune_trainable_b6a12_00064_64_model::dropou...   MNIST   \n",
       "39858       39858  NN_tune_trainable_b6a12_00096_96_model::dropou...   MNIST   \n",
       "39873       39873  NN_tune_trainable_b6a12_00128_128_model::dropo...   MNIST   \n",
       "39884       39884  NN_tune_trainable_b6a12_00224_224_model::dropo...   MNIST   \n",
       "40002       40002  NN_tune_trainable_b6a12_00192_192_model::dropo...   MNIST   \n",
       "40215       40215  NN_tune_trainable_b6a12_00097_97_model::dropou...   MNIST   \n",
       "40224       40224  NN_tune_trainable_b6a12_00000_0_model::dropout...   MNIST   \n",
       "40314       40314  NN_tune_trainable_b6a12_00065_65_model::dropou...   MNIST   \n",
       "40418       40418  NN_tune_trainable_b6a12_00225_225_model::dropo...   MNIST   \n",
       "40602       40602  NN_tune_trainable_b6a12_00032_32_model::dropou...   MNIST   \n",
       "40642       40642  NN_tune_trainable_b6a12_00033_33_model::dropou...   MNIST   \n",
       "40698       40698  NN_tune_trainable_b6a12_00001_1_model::dropout...   MNIST   \n",
       "\n",
       "      attack     setup  eps  dropout init_type  nlin      lr  momentum  \\\n",
       "38557    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0001       0.9   \n",
       "38768    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0001       0.9   \n",
       "38835    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0010       0.9   \n",
       "38848    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0010       0.9   \n",
       "39431    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0010       0.9   \n",
       "39858    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0001       0.9   \n",
       "39873    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0010       0.9   \n",
       "39884    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0001       0.9   \n",
       "40002    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0010       0.9   \n",
       "40215    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0001       0.9   \n",
       "40224    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0010       0.9   \n",
       "40314    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0010       0.9   \n",
       "40418    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0001       0.9   \n",
       "40602    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.0001       0.9   \n",
       "40642    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0001       0.9   \n",
       "40698    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.0010       0.9   \n",
       "\n",
       "      optimizer      wd  seed  old_loss  old_acc  new_loss  new_acc  \n",
       "38557      adam  0.0001     1     0.974    0.657  0.099562   0.6483  \n",
       "38768      adam  0.0001     1     0.261    0.920  0.108685   0.6873  \n",
       "38835      adam  0.0001     1     0.201    0.939  0.505041   0.1157  \n",
       "38848       sgd  0.0001     1     0.488    0.844  0.210894   0.4070  \n",
       "39431       sgd  0.0010     1     0.076    0.978  0.279926   0.3897  \n",
       "39858       sgd  0.0010     1     2.301    0.113  0.230131   0.1135  \n",
       "39873      adam  0.0001     1     0.085    0.973  0.179025   0.5630  \n",
       "39884       sgd  0.0001     1     2.301    0.113  0.230131   0.1135  \n",
       "40002       sgd  0.0001     1     2.303    0.100  0.230614   0.1135  \n",
       "40215       sgd  0.0010     1     2.278    0.140  0.230251   0.1009  \n",
       "40224      adam  0.0010     1     0.061    0.982  0.189798   0.5193  \n",
       "40314       sgd  0.0010     1     0.165    0.950  0.486701   0.1259  \n",
       "40418       sgd  0.0001     1     2.293    0.134  0.230215   0.1135  \n",
       "40602      adam  0.0010     1     0.138    0.958  0.340227   0.3015  \n",
       "40642      adam  0.0010     1     0.457    0.857  0.146339   0.5740  \n",
       "40698      adam  0.0010     1     0.143    0.958  0.458088   0.1135  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a7be7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model_paths = df[\"name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eea05519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN_tune_trainable_143c9_00001_1_model::dropout=0.5,model::init_type=uniform,model::nlin=tanh,optim::optimizer=adam,optim::wd=0.01,_2021-09-22_09-40-12'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f0a9fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>attack</th>\n",
       "      <th>setup</th>\n",
       "      <th>eps</th>\n",
       "      <th>dropout</th>\n",
       "      <th>init_type</th>\n",
       "      <th>nlin</th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>seed</th>\n",
       "      <th>old_loss</th>\n",
       "      <th>old_acc</th>\n",
       "      <th>new_loss</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64271</th>\n",
       "      <td>64271</td>\n",
       "      <td>NN_tune_trainable_143c9_00001_1_model::dropout...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.575</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>0.1682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               name  dataset  \\\n",
       "64271       64271  NN_tune_trainable_143c9_00001_1_model::dropout...  CIFAR10   \n",
       "\n",
       "      attack     setup  eps  dropout init_type  nlin     lr  momentum  \\\n",
       "64271    PGD  hyp-10-f  0.1      0.5   uniform  tanh  0.001       0.9   \n",
       "\n",
       "      optimizer    wd  seed  old_loss  old_acc  new_loss  new_acc  \n",
       "64271      adam  0.01     1     1.575     0.44  0.229315   0.1682  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[df.name==updated_model_paths[0]]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f313b7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.575"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"old_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d20394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdacd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c38d68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which models should be deleted from the model_paths \n",
    "# 1. the models containing nan\n",
    "a = 0\n",
    "aux = False\n",
    "for i, path in enumerate(updated_model_paths):\n",
    "        \n",
    "    checkpoints = []\n",
    "    for p in os.listdir(os.path.join(result_path, path)):\n",
    "        if p.startswith(\"checkpoint\"):\n",
    "            checkpoints.append(p)\n",
    "    checkpoints.sort()\n",
    "    result_model_path = os.path.join(result_path, path, checkpoints[-1], \"checkpoints\")\n",
    "    state_dict = torch.load(result_model_path)\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if aux:\n",
    "            continue\n",
    "        if torch.isnan(value).any():\n",
    "            del updated_model[i]\n",
    "            a += 1\n",
    "            aux = True\n",
    "    \n",
    "    aux = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8f529b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. the models with bad performance\n",
    "for i, path in enumerate(updated_model_paths):\n",
    "    if df[df.name==path].iloc[0, 15] <= 0.2:\n",
    "        del updated_model_paths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "34aa4b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4d3c2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, path in enumerate(updated_model_paths):\n",
    "    checkpoints = []\n",
    "    for p in os.listdir(os.path.join(result_path, path)):\n",
    "        if p.startswith(\"checkpoint\"):\n",
    "            checkpoints.append(p)\n",
    "    checkpoints.sort()\n",
    "    result_model_path = os.path.join(result_path, path, checkpoints[-1], \"checkpoints\")\n",
    "    state_dict = torch.load(result_model_path)\n",
    "    \n",
    "    if i == 0:    \n",
    "        uniform_soup = {k: v * (1./(len(updated_model_paths))) for k, v in state_dict.items()}\n",
    "    else:\n",
    "        uniform_soup = {k: v * (1./(len(updated_model_paths))) + uniform_soup[k] for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6e5fe092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>attack</th>\n",
       "      <th>setup</th>\n",
       "      <th>eps</th>\n",
       "      <th>dropout</th>\n",
       "      <th>init_type</th>\n",
       "      <th>nlin</th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>seed</th>\n",
       "      <th>old_loss</th>\n",
       "      <th>old_acc</th>\n",
       "      <th>new_loss</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64315</th>\n",
       "      <td>64315</td>\n",
       "      <td>NN_tune_trainable_143c9_00064_64_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.237703</td>\n",
       "      <td>0.2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71510</th>\n",
       "      <td>71510</td>\n",
       "      <td>NN_tune_trainable_143c9_00064_64_model::dropou...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.245964</td>\n",
       "      <td>0.2666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               name  dataset  \\\n",
       "64315       64315  NN_tune_trainable_143c9_00064_64_model::dropou...  CIFAR10   \n",
       "71510       71510  NN_tune_trainable_143c9_00064_64_model::dropou...  CIFAR10   \n",
       "\n",
       "      attack     setup  eps  dropout init_type  nlin     lr  momentum  \\\n",
       "64315    PGD  hyp-10-f  0.1      0.0   uniform  tanh  0.001       0.9   \n",
       "71510   FGSM  hyp-10-f  0.1      0.0   uniform  tanh  0.001       0.9   \n",
       "\n",
       "      optimizer     wd  seed  old_loss  old_acc  new_loss  new_acc  \n",
       "64315      adam  0.001     1     0.968    0.663  0.237703   0.2892  \n",
       "71510      adam  0.001     1     0.968    0.663  0.245964   0.2666  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.old_acc == df.old_acc.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ed152e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 1000.0 done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(uniform_soup)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtestset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoup: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, model, config_model)\u001b[0m\n\u001b[1;32m     30\u001b[0m imgs, labels \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m n_b \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     36\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mequal(np\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     37\u001b[0m     labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/netscratch2/jlautz/model_robustness/src/model_robustness/attacks/networks.py:103\u001b[0m, in \u001b[0;36mConvNetSmall.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_list:\n\u001b[0;32m--> 103\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_config_path = os.path.join(ROOT, result_path, df[df.old_acc == df.old_acc.max()].iloc[0,1], \"params.json\")\n",
    "config_model = json.load(open(model_config_path, ))\n",
    "device = \"cpu\"\n",
    "\n",
    "model = ConvNetSmall(\n",
    "    channels_in=config_model[\"model::channels_in\"],\n",
    "    nlin=config_model[\"model::nlin\"],\n",
    "    dropout=0.0,\n",
    "    init_type=config_model[\"model::init_type\"]\n",
    ")\n",
    "model.load_state_dict(uniform_soup)\n",
    "model.to(device)\n",
    "\n",
    "loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "09f03351",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_dict = torch.load(\"../../data/soup_model1.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "642fd6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.positional_embedding\n",
      "model.text_projection\n",
      "model.logit_scale\n",
      "model.visual.class_embedding\n",
      "model.visual.positional_embedding\n",
      "model.visual.proj\n",
      "model.visual.conv1.weight\n",
      "model.visual.ln_pre.weight\n",
      "model.visual.ln_pre.bias\n",
      "model.visual.transformer.resblocks.0.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.0.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.0.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.0.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.0.ln_1.weight\n",
      "model.visual.transformer.resblocks.0.ln_1.bias\n",
      "model.visual.transformer.resblocks.0.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.0.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.0.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.0.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.0.ln_2.weight\n",
      "model.visual.transformer.resblocks.0.ln_2.bias\n",
      "model.visual.transformer.resblocks.1.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.1.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.1.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.1.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.1.ln_1.weight\n",
      "model.visual.transformer.resblocks.1.ln_1.bias\n",
      "model.visual.transformer.resblocks.1.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.1.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.1.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.1.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.1.ln_2.weight\n",
      "model.visual.transformer.resblocks.1.ln_2.bias\n",
      "model.visual.transformer.resblocks.2.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.2.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.2.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.2.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.2.ln_1.weight\n",
      "model.visual.transformer.resblocks.2.ln_1.bias\n",
      "model.visual.transformer.resblocks.2.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.2.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.2.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.2.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.2.ln_2.weight\n",
      "model.visual.transformer.resblocks.2.ln_2.bias\n",
      "model.visual.transformer.resblocks.3.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.3.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.3.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.3.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.3.ln_1.weight\n",
      "model.visual.transformer.resblocks.3.ln_1.bias\n",
      "model.visual.transformer.resblocks.3.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.3.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.3.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.3.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.3.ln_2.weight\n",
      "model.visual.transformer.resblocks.3.ln_2.bias\n",
      "model.visual.transformer.resblocks.4.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.4.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.4.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.4.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.4.ln_1.weight\n",
      "model.visual.transformer.resblocks.4.ln_1.bias\n",
      "model.visual.transformer.resblocks.4.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.4.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.4.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.4.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.4.ln_2.weight\n",
      "model.visual.transformer.resblocks.4.ln_2.bias\n",
      "model.visual.transformer.resblocks.5.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.5.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.5.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.5.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.5.ln_1.weight\n",
      "model.visual.transformer.resblocks.5.ln_1.bias\n",
      "model.visual.transformer.resblocks.5.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.5.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.5.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.5.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.5.ln_2.weight\n",
      "model.visual.transformer.resblocks.5.ln_2.bias\n",
      "model.visual.transformer.resblocks.6.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.6.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.6.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.6.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.6.ln_1.weight\n",
      "model.visual.transformer.resblocks.6.ln_1.bias\n",
      "model.visual.transformer.resblocks.6.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.6.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.6.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.6.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.6.ln_2.weight\n",
      "model.visual.transformer.resblocks.6.ln_2.bias\n",
      "model.visual.transformer.resblocks.7.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.7.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.7.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.7.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.7.ln_1.weight\n",
      "model.visual.transformer.resblocks.7.ln_1.bias\n",
      "model.visual.transformer.resblocks.7.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.7.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.7.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.7.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.7.ln_2.weight\n",
      "model.visual.transformer.resblocks.7.ln_2.bias\n",
      "model.visual.transformer.resblocks.8.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.8.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.8.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.8.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.8.ln_1.weight\n",
      "model.visual.transformer.resblocks.8.ln_1.bias\n",
      "model.visual.transformer.resblocks.8.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.8.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.8.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.8.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.8.ln_2.weight\n",
      "model.visual.transformer.resblocks.8.ln_2.bias\n",
      "model.visual.transformer.resblocks.9.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.9.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.9.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.9.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.9.ln_1.weight\n",
      "model.visual.transformer.resblocks.9.ln_1.bias\n",
      "model.visual.transformer.resblocks.9.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.9.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.9.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.9.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.9.ln_2.weight\n",
      "model.visual.transformer.resblocks.9.ln_2.bias\n",
      "model.visual.transformer.resblocks.10.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.10.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.10.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.10.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.10.ln_1.weight\n",
      "model.visual.transformer.resblocks.10.ln_1.bias\n",
      "model.visual.transformer.resblocks.10.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.10.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.10.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.10.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.10.ln_2.weight\n",
      "model.visual.transformer.resblocks.10.ln_2.bias\n",
      "model.visual.transformer.resblocks.11.attn.in_proj_weight\n",
      "model.visual.transformer.resblocks.11.attn.in_proj_bias\n",
      "model.visual.transformer.resblocks.11.attn.out_proj.weight\n",
      "model.visual.transformer.resblocks.11.attn.out_proj.bias\n",
      "model.visual.transformer.resblocks.11.ln_1.weight\n",
      "model.visual.transformer.resblocks.11.ln_1.bias\n",
      "model.visual.transformer.resblocks.11.mlp.c_fc.weight\n",
      "model.visual.transformer.resblocks.11.mlp.c_fc.bias\n",
      "model.visual.transformer.resblocks.11.mlp.c_proj.weight\n",
      "model.visual.transformer.resblocks.11.mlp.c_proj.bias\n",
      "model.visual.transformer.resblocks.11.ln_2.weight\n",
      "model.visual.transformer.resblocks.11.ln_2.bias\n",
      "model.visual.ln_post.weight\n",
      "model.visual.ln_post.bias\n",
      "model.token_embedding.weight\n",
      "model.ln_final.weight\n",
      "model.ln_final.bias\n",
      "classification_head.weight\n",
      "classification_head.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in soup_dict.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce3ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c77eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc2e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce8acbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 14/1280 contains NaNs and is skipped\n",
      "Model 32/1280 contains NaNs and is skipped\n"
     ]
    }
   ],
   "source": [
    "aux = False\n",
    "for i, path in enumerate(model_paths):\n",
    "    result_model_path = os.path.join(result_path, path, \"checkpoint_000050\", \"checkpoints\")\n",
    "    state_dict = torch.load(result_model_path)\n",
    "    for key, value in state_dict.items():\n",
    "        if aux:\n",
    "            continue \n",
    "        if torch.isnan(value).any():\n",
    "            a += 1\n",
    "            print(f\"Model {i+1}/{len(model_paths)} contains NaNs and is skipped\")\n",
    "            \n",
    "            aux = True\n",
    "        elif df[df.name==path].iloc[0, 15] >= 0.2:\n",
    "            aux = True\n",
    "\n",
    "    if aux:\n",
    "        pass\n",
    "    else:\n",
    "        if i == 0:    \n",
    "            uniform_soup = {k: v * (1./(len(model_paths)-86)) for k, v in state_dict.items()}\n",
    "        else:\n",
    "            uniform_soup = {k: v * (1./(len(model_paths)-86)) + uniform_soup[k] for k, v in state_dict.items()}\n",
    "    aux = False\n",
    "    if i == 66:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16b78ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0273, 0.0300, 0.0382])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_soup[\"module_list.0.weight\"][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7701d488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 14/1280 contains NaNs and is skipped\n",
      "Model 32/1280 contains NaNs and is skipped\n",
      "Model 78/1280 contains NaNs and is skipped\n",
      "Model 110/1280 contains NaNs and is skipped\n",
      "Model 126/1280 contains NaNs and is skipped\n",
      "Model 142/1280 contains NaNs and is skipped\n",
      "Model 176/1280 contains NaNs and is skipped\n",
      "Model 177/1280 contains NaNs and is skipped\n",
      "Model 187/1280 contains NaNs and is skipped\n",
      "Model 191/1280 contains NaNs and is skipped\n",
      "Model 199/1280 contains NaNs and is skipped\n",
      "Model 211/1280 contains NaNs and is skipped\n",
      "Model 226/1280 contains NaNs and is skipped\n",
      "Model 234/1280 contains NaNs and is skipped\n",
      "Model 241/1280 contains NaNs and is skipped\n",
      "Model 272/1280 contains NaNs and is skipped\n",
      "Model 304/1280 contains NaNs and is skipped\n",
      "Model 320/1280 contains NaNs and is skipped\n",
      "Model 325/1280 contains NaNs and is skipped\n",
      "Model 339/1280 contains NaNs and is skipped\n",
      "Model 340/1280 contains NaNs and is skipped\n",
      "Model 341/1280 contains NaNs and is skipped\n",
      "Model 345/1280 contains NaNs and is skipped\n",
      "Model 363/1280 contains NaNs and is skipped\n",
      "Model 407/1280 contains NaNs and is skipped\n",
      "Model 447/1280 contains NaNs and is skipped\n",
      "Model 454/1280 contains NaNs and is skipped\n",
      "Model 460/1280 contains NaNs and is skipped\n",
      "Model 488/1280 contains NaNs and is skipped\n",
      "Model 490/1280 contains NaNs and is skipped\n",
      "Model 557/1280 contains NaNs and is skipped\n",
      "Model 572/1280 contains NaNs and is skipped\n",
      "Model 582/1280 contains NaNs and is skipped\n",
      "Model 614/1280 contains NaNs and is skipped\n",
      "Model 617/1280 contains NaNs and is skipped\n",
      "Model 633/1280 contains NaNs and is skipped\n",
      "Model 638/1280 contains NaNs and is skipped\n",
      "Model 646/1280 contains NaNs and is skipped\n",
      "Model 654/1280 contains NaNs and is skipped\n",
      "Model 696/1280 contains NaNs and is skipped\n",
      "Model 714/1280 contains NaNs and is skipped\n",
      "Model 777/1280 contains NaNs and is skipped\n",
      "Model 781/1280 contains NaNs and is skipped\n",
      "Model 805/1280 contains NaNs and is skipped\n",
      "Model 874/1280 contains NaNs and is skipped\n",
      "Model 876/1280 contains NaNs and is skipped\n",
      "Model 880/1280 contains NaNs and is skipped\n",
      "Model 896/1280 contains NaNs and is skipped\n",
      "Model 924/1280 contains NaNs and is skipped\n",
      "Model 958/1280 contains NaNs and is skipped\n",
      "Model 961/1280 contains NaNs and is skipped\n",
      "Model 984/1280 contains NaNs and is skipped\n",
      "Model 993/1280 contains NaNs and is skipped\n",
      "Model 994/1280 contains NaNs and is skipped\n",
      "Model 996/1280 contains NaNs and is skipped\n",
      "Model 1023/1280 contains NaNs and is skipped\n",
      "Model 1024/1280 contains NaNs and is skipped\n",
      "Model 1055/1280 contains NaNs and is skipped\n",
      "Model 1064/1280 contains NaNs and is skipped\n",
      "Model 1075/1280 contains NaNs and is skipped\n",
      "Model 1079/1280 contains NaNs and is skipped\n",
      "Model 1123/1280 contains NaNs and is skipped\n",
      "Model 1147/1280 contains NaNs and is skipped\n",
      "Model 1148/1280 contains NaNs and is skipped\n",
      "Model 1164/1280 contains NaNs and is skipped\n",
      "Model 1167/1280 contains NaNs and is skipped\n",
      "Model 1256/1280 contains NaNs and is skipped\n",
      "Model 1279/1280 contains NaNs and is skipped\n",
      "Uniform soup contains 1212/1280 models.\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "aux = False\n",
    "for i, path in enumerate(model_paths):\n",
    "    result_model_path = os.path.join(result_path, path, \"checkpoint_000050\", \"checkpoints\")\n",
    "    \n",
    "    assert os.path.exists(result_model_path)\n",
    "    \n",
    "    state_dict = torch.load(result_model_path)\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if aux:\n",
    "            continue \n",
    "        if torch.isnan(value).any():\n",
    "            a += 1\n",
    "            print(f\"Model {i+1}/{len(model_paths)} contains NaNs and is skipped\")\n",
    "            \n",
    "            aux = True\n",
    "\n",
    "    if aux:\n",
    "        pass\n",
    "    else:\n",
    "        if i == 0:    \n",
    "            uniform_soup = {k: v * (1./(len(model_paths)-86)) for k, v in state_dict.items()}\n",
    "        else:\n",
    "            uniform_soup = {k: v * (1./(len(model_paths)-86)) + uniform_soup[k] for k, v in state_dict.items()}\n",
    "    aux = False\n",
    "print(f\"Uniform soup contains {len(model_paths) - a}/{len(model_paths)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48514cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3359147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration of best model\n",
    "zoo_path = os.path.join(ROOT, \"/ds2/model_zoos/zoos_v2/CIFAR10/large/analysis_data_hyp_fix.pt\")\n",
    "zoo = torch.load(zoo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa574383",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "index_list = [50]\n",
    "path_list = []\n",
    "for i in range(len(zoo[\"paths\"])):\n",
    "    if i == 0:\n",
    "        aux = zoo[\"paths\"][i]\n",
    "        path_list.append(zoo[\"paths\"][i])\n",
    "\n",
    "    if zoo[\"paths\"][i] == aux:\n",
    "        pass\n",
    "    else:\n",
    "        a += 1\n",
    "        index_list.append(i+50)\n",
    "        aux = zoo[\"paths\"][i]\n",
    "        path_list.append(aux)\n",
    "\n",
    "for i in range(len(path_list)):\n",
    "    path_list[i] = path_list[i].__str__().split(\"/\")[-1]\n",
    "\n",
    "# Get all accuracies\n",
    "acc_list = []\n",
    "for index in index_list:\n",
    "    acc_list.append(zoo[\"acc\"][index])\n",
    "\n",
    "# Get the index of max element\n",
    "max_index = acc_list.index(max(acc_list))\n",
    "\n",
    "# Get the corresponding model name\n",
    "best_model_path = path_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32b03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, model, config_model):\n",
    "\n",
    "    # Define dataloader for evaluation\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config_model[\"training::batchsize\"],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Define criterion and optimizer\n",
    "    if config_model[\"optim::optimizer\"] == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config_model[\"optim::lr\"], \n",
    "            momentum=config_model[\"optim::momentum\"], weight_decay=config_model[\"optim::wd\"])\n",
    "\n",
    "    elif config_model[\"optim::optimizer\"] == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config_model[\"optim::lr\"], \n",
    "            weight_decay=config_model[\"optim::wd\"])\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Evaluate        \n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "\n",
    "    for j, data in enumerate(loader):\n",
    "                \n",
    "        model.eval()\n",
    "\n",
    "        imgs, labels = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        n_b = labels.shape[0]\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        acc = np.sum(np.equal(np.argmax(outputs.cpu().data.numpy(), axis=-1),\n",
    "            labels.cpu().data.numpy()))\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "        if j % 250 == 0:\n",
    "            print(f\"Batch {j} of {len(dataset)/config_model['training::batchsize']} done.\")\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c123ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 1000.0 done.\n",
      "Batch 250 of 1000.0 done.\n",
      "Batch 500 of 1000.0 done.\n",
      "Batch 750 of 1000.0 done.\n",
      "Soup: Loss = 0.08775529526546598, Accuracy = 0.7023\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvNetLarge:\n\tMissing key(s) in state_dict: \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.6.weight\", \"module_list.6.bias\", \"module_list.10.weight\", \"module_list.10.bias\", \"module_list.12.weight\", \"module_list.12.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.13.weight\", \"module_list.13.bias\", \"module_list.16.weight\", \"module_list.16.bias\", \"module_list.4.weight\", \"module_list.4.bias\", \"module_list.8.weight\", \"module_list.8.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m ConvNetLarge(\n\u001b[1;32m     23\u001b[0m         channels_in\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::channels_in\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     24\u001b[0m         nlin\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::nlin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::dropout\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m         init_type\u001b[38;5;241m=\u001b[39mconfig_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel::init_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniform_soup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m evaluate(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestset\u001b[39m\u001b[38;5;124m\"\u001b[39m], model, config_model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNetLarge:\n\tMissing key(s) in state_dict: \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.6.weight\", \"module_list.6.bias\", \"module_list.10.weight\", \"module_list.10.bias\", \"module_list.12.weight\", \"module_list.12.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.13.weight\", \"module_list.13.bias\", \"module_list.16.weight\", \"module_list.16.bias\", \"module_list.4.weight\", \"module_list.4.bias\", \"module_list.8.weight\", \"module_list.8.bias\". "
     ]
    }
   ],
   "source": [
    "model_config_path = os.path.join(ROOT, result_path, best_model_path, \"params.json\")\n",
    "config_model = json.load(open(model_config_path, ))\n",
    "device = \"cpu\"\n",
    "\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        model = ConvNetLarge(\n",
    "            channels_in=config_model[\"model::channels_in\"],\n",
    "            nlin=config_model[\"model::nlin\"],\n",
    "            dropout=0.5,\n",
    "            init_type=config_model[\"model::init_type\"]\n",
    "        )\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(ROOT, result_path, best_model_path, \"checkpoint_000050\", \"checkpoints\"), map_location=torch.device(device))\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "        print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")\n",
    "    \n",
    "    else:\n",
    "        model = ConvNetLarge(\n",
    "            channels_in=config_model[\"model::channels_in\"],\n",
    "            nlin=config_model[\"model::nlin\"],\n",
    "            dropout=0.5,\n",
    "            init_type=config_model[\"model::init_type\"]\n",
    "        )\n",
    "        model.load_state_dict(uniform_soup)\n",
    "        model.to(device)\n",
    "        \n",
    "        loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "        print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f522acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/all_results.csv\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a698ea97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN_tune_trainable_143c9_00090_90_model::dropout=0,model::init_type=normal,model::nlin=gelu,optim::optimizer=adam,optim::wd=0.001,s_2021-09-22_14-12-28'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6156d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>attack</th>\n",
       "      <th>setup</th>\n",
       "      <th>eps</th>\n",
       "      <th>dropout</th>\n",
       "      <th>init_type</th>\n",
       "      <th>nlin</th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>seed</th>\n",
       "      <th>old_loss</th>\n",
       "      <th>old_acc</th>\n",
       "      <th>new_loss</th>\n",
       "      <th>new_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65126</th>\n",
       "      <td>65126</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66342</th>\n",
       "      <td>66342</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67215</th>\n",
       "      <td>67215</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67949</th>\n",
       "      <td>67949</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70346</th>\n",
       "      <td>70346</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>PGD</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70739</th>\n",
       "      <td>70739</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72786</th>\n",
       "      <td>72786</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74221</th>\n",
       "      <td>74221</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74991</th>\n",
       "      <td>74991</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75970</th>\n",
       "      <td>75970</td>\n",
       "      <td>NN_tune_trainable_143c9_00376_376_model::dropo...</td>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>hyp-10-f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.230322</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               name  dataset  \\\n",
       "65126       65126  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "66342       66342  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "67215       67215  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "67949       67949  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "70346       70346  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "70739       70739  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "72786       72786  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "74221       74221  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "74991       74991  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "75970       75970  NN_tune_trainable_143c9_00376_376_model::dropo...  CIFAR10   \n",
       "\n",
       "      attack     setup  eps  dropout init_type  nlin     lr  momentum  \\\n",
       "65126    PGD  hyp-10-f  0.1      0.0   uniform  gelu  0.001       0.9   \n",
       "66342    PGD  hyp-10-f  0.2      0.0   uniform  gelu  0.001       0.9   \n",
       "67215    PGD  hyp-10-f  0.3      0.0   uniform  gelu  0.001       0.9   \n",
       "67949    PGD  hyp-10-f  0.4      0.0   uniform  gelu  0.001       0.9   \n",
       "70346    PGD  hyp-10-f  0.5      0.0   uniform  gelu  0.001       0.9   \n",
       "70739   FGSM  hyp-10-f  0.1      0.0   uniform  gelu  0.001       0.9   \n",
       "72786   FGSM  hyp-10-f  0.2      0.0   uniform  gelu  0.001       0.9   \n",
       "74221   FGSM  hyp-10-f  0.3      0.0   uniform  gelu  0.001       0.9   \n",
       "74991   FGSM  hyp-10-f  0.4      0.0   uniform  gelu  0.001       0.9   \n",
       "75970   FGSM  hyp-10-f  0.5      0.0   uniform  gelu  0.001       0.9   \n",
       "\n",
       "      optimizer     wd  seed  old_loss  old_acc  new_loss  new_acc  \n",
       "65126       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "66342       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "67215       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "67949       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "70346       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "70739       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "72786       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "74221       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "74991       sgd  0.001     3     2.309    0.096  0.230322      0.1  \n",
       "75970       sgd  0.001     3     2.309    0.096  0.230322      0.1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.name==model_paths[67]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e0a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a014cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841c2a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 1000.0 done.\n",
      "Batch 250 of 1000.0 done.\n",
      "Batch 500 of 1000.0 done.\n",
      "Batch 750 of 1000.0 done.\n",
      "Soup: Loss = nan, Accuracy = 0.1\n"
     ]
    }
   ],
   "source": [
    "model_config_path = os.path.join(ROOT, result_path, best_model_path, \"params.json\")\n",
    "config_model = json.load(open(model_config_path, ))\n",
    "device = \"cpu\"\n",
    "\n",
    "model = ConvNetLarge(\n",
    "    channels_in=config_model[\"model::channels_in\"],\n",
    "    nlin=config_model[\"model::nlin\"],\n",
    "    dropout=0.5,\n",
    "    init_type=config_model[\"model::init_type\"]\n",
    ")\n",
    "model.load_state_dict(uniform_soup)\n",
    "model.to(device)\n",
    "\n",
    "loss, acc = evaluate(ds[\"testset\"], model, config_model)\n",
    "print(f\"Soup: Loss = {loss}, Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92ef7523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-6.301056e+09, dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_soup[\"module_list.0.weight\"][0][0][0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beaeb3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0145, -0.3294,  0.2620],\n",
       "        [-0.3636,  0.1903,  0.3682],\n",
       "        [ 0.1038,  0.3367, -0.3192]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(os.path.join(ROOT, result_path, best_model_path, \"checkpoint_000050\", \"checkpoints\"), map_location=torch.device(device))[\"module_list.0.weight\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689512b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
