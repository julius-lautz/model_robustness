{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f99abe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "source code string cannot contain null bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, TensorDataset\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_split\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_tokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetTokens\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit_re_basin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit_re_basin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     resnet18_permutation_spec,\n\u001b[1;32m     18\u001b[0m     zoo_cnn_large_permutation_spec,\n\u001b[1;32m     19\u001b[0m     zoo_cnn_permutation_spec)\n\u001b[1;32m     21\u001b[0m ROOT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/netscratch2/jlautz/model_robustness/src/model_robustness/attacks/shrp/datasets/dataset_tokens.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m factorial\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_epochs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelDatasetBaseEpochs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshrp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit_re_basin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit_re_basin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     PermutationSpec,\n\u001b[1;32m     14\u001b[0m     zoo_cnn_permutation_spec,\n\u001b[1;32m     15\u001b[0m     weight_matching,\n\u001b[1;32m     16\u001b[0m     apply_permutation,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_auxiliaries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# tokens_to_checkpoint,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     tokenize_checkpoint,\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: source code string cannot contain null bytes"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from shrp.datasets.dataset_tokens import DatasetTokens\n",
    "from shrp.git_re_basin.git_re_basin import (\n",
    "    resnet18_permutation_spec,\n",
    "    zoo_cnn_large_permutation_spec,\n",
    "    zoo_cnn_permutation_spec)\n",
    "\n",
    "ROOT = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692c9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_path = Path(\"/ds2/model_zoos/zoos_v2/MNIST/tune_zoo_mnist_uniform/\")\n",
    "\n",
    "result_key_list = [\"test_acc\", \"training_iteration\"]\n",
    "config_key_list = []\n",
    "property_keys = {\n",
    "    \"result_keys\": result_key_list,\n",
    "    \"config_keys\": config_key_list\n",
    "}\n",
    "tokensize=0\n",
    "permutation_spec = zoo_cnn_permutation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd8c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rdx in [zoo_path.absolute()]:\n",
    "    a = [f for f in rdx.iterdir() if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5f3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrp.datasets.dataset_base import load_checkpoint\n",
    "epoch_lst = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93ffef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdx in a:\n",
    "    for e in range(1):\n",
    "        ep = epoch_lst[e-1]\n",
    "        \n",
    "        ref_check, ref_lab, ref_path, ref_ep = load_checkpoint(\n",
    "            path=pdx,\n",
    "            edx=ep,\n",
    "            weight_threshold=float(\"inf\"),\n",
    "            filter_function=None\n",
    "        )\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a3d3073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"ds_split\": [0.7, 0.15, 0.15],\n",
    "    \"getitem\": \"tokens+props\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc4df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to set how datasets should be downloaded. set in single place to ensure \n",
    "dataset_config = {\n",
    "    'epoch_lst' : 50,\n",
    "    'mode' : \"vector\",\n",
    "    'permutation_spec' : permutation_spec,\n",
    "    'map_to_canonical' : False,\n",
    "    'standardize' : \"l2_ind\",\n",
    "    'ds_split' : [1.0],  \n",
    "    'max_samples' : 1000,\n",
    "    'weight_threshold' : 15000,\n",
    "    'precision' : \"32\",\n",
    "    'filter_function' : None,  # gets sample path as argument and returns True if model needs to be filtered out\n",
    "    'num_threads' : 8,\n",
    "    'shuffle_path' : True,\n",
    "    'verbosity' : 3,\n",
    "    'getitem' : \"tokens+props\",\n",
    "    'ignore_bn' : False,\n",
    "    'tokensize' : tokensize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66bc95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:dataset splits are unintelligble. Load 100% of dataset\n",
      "2023-08-17 11:30:24,601\tWARNING services.py:1780 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1073741824 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=2.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-08-17 11:30:25,697\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:19<00:00, 51.93it/s]\n",
      "1000it [01:32, 10.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2529.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 939.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#trainset = DatasetTokens(root=[zoo_path.absolute()], train_val_test='train',  property_keys=property_keys, **dataset_config)\n",
    "testset = DatasetTokens(root=[zoo_path.absolute()], train_val_test='test',  property_keys=property_keys, **dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfba92e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9c65df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__get_paths__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtestset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_paths__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/netscratch2/jlautz/model_robustness/src/model_robustness/attacks/shrp/datasets/dataset_tokens.py:291\u001b[0m, in \u001b[0;36mDatasetTokens.__get_paths__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_paths__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_paths__\u001b[49m(index)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__get_paths__'"
     ]
    }
   ],
   "source": [
    "testset.__get_paths__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e745eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0136,  0.0125,  0.0753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0114,  0.0386, -0.0020,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0549, -0.0086, -0.0125,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0779,  0.0552, -0.1352,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0302,  0.0685,  0.0684,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0154,  0.0507, -0.0480,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]]),\n",
       " tensor([[ 0,  0,  0],\n",
       "         [ 1,  0,  1],\n",
       "         [ 2,  0,  2],\n",
       "         [ 3,  0,  3],\n",
       "         [ 4,  0,  4],\n",
       "         [ 5,  0,  5],\n",
       "         [ 6,  0,  6],\n",
       "         [ 7,  0,  7],\n",
       "         [ 8,  1,  0],\n",
       "         [ 9,  1,  1],\n",
       "         [10,  1,  2],\n",
       "         [11,  1,  3],\n",
       "         [12,  1,  4],\n",
       "         [13,  1,  5],\n",
       "         [14,  2,  0],\n",
       "         [15,  2,  1],\n",
       "         [16,  2,  2],\n",
       "         [17,  2,  3],\n",
       "         [18,  3,  0],\n",
       "         [19,  3,  1],\n",
       "         [20,  3,  2],\n",
       "         [21,  3,  3],\n",
       "         [22,  3,  4],\n",
       "         [23,  3,  5],\n",
       "         [24,  3,  6],\n",
       "         [25,  3,  7],\n",
       "         [26,  3,  8],\n",
       "         [27,  3,  9],\n",
       "         [28,  3, 10],\n",
       "         [29,  3, 11],\n",
       "         [30,  3, 12],\n",
       "         [31,  3, 13],\n",
       "         [32,  3, 14],\n",
       "         [33,  3, 15],\n",
       "         [34,  3, 16],\n",
       "         [35,  3, 17],\n",
       "         [36,  3, 18],\n",
       "         [37,  3, 19],\n",
       "         [38,  4,  0],\n",
       "         [39,  4,  1],\n",
       "         [40,  4,  2],\n",
       "         [41,  4,  3],\n",
       "         [42,  4,  4],\n",
       "         [43,  4,  5],\n",
       "         [44,  4,  6],\n",
       "         [45,  4,  7],\n",
       "         [46,  4,  8],\n",
       "         [47,  4,  9]], dtype=torch.int32),\n",
       " tensor([ 0.9080, 50.0000]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24405d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_acc', 'training_iteration'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.properties.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03102bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa29046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
