{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faae23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from shrp.datasets.dataset_tokens import DatasetTokens\n",
    "from shrp.git_re_basin.git_re_basin import (\n",
    "    resnet18_permutation_spec,\n",
    "    zoo_cnn_large_permutation_spec,\n",
    "    zoo_cnn_permutation_spec)\n",
    "\n",
    "ROOT = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33630260",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_path = Path(\"/ds2/model_zoos/zoos_v2/MNIST/tune_zoo_mnist_uniform/\")\n",
    "\n",
    "result_key_list = [\"test_acc\", \"training_iteration\"]\n",
    "config_key_list = []\n",
    "property_keys = {\n",
    "    \"result_keys\": result_key_list,\n",
    "    \"config_keys\": config_key_list\n",
    "}\n",
    "tokensize=0\n",
    "permutation_spec = zoo_cnn_permutation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da7e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rdx in [zoo_path.absolute()]:\n",
    "    a = [f for f in rdx.iterdir() if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cec5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrp.datasets.dataset_base import load_checkpoint\n",
    "epoch_lst = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35a89b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdx in a:\n",
    "    for e in range(1):\n",
    "        ep = epoch_lst[e-1]\n",
    "        \n",
    "        ref_check, ref_lab, ref_path, ref_ep = load_checkpoint(\n",
    "            path=pdx,\n",
    "            edx=ep,\n",
    "            weight_threshold=float(\"inf\"),\n",
    "            filter_function=None\n",
    "        )\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b0f3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"ds_split\": [0.7, 0.15, 0.15],\n",
    "    \"getitem\": \"tokens+props\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "342a9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to set how datasets should be downloaded. set in single place to ensure \n",
    "dataset_config = {\n",
    "    'epoch_lst' : 50,\n",
    "    'mode' : \"vector\",\n",
    "    'permutation_spec' : permutation_spec,\n",
    "    'map_to_canonical' : False,\n",
    "    'standardize' : \"l2_ind\",\n",
    "    'ds_split' : [1.0],  \n",
    "    'max_samples' : 1000,\n",
    "    'weight_threshold' : 15000,\n",
    "    'precision' : \"32\",\n",
    "    'filter_function' : None,  # gets sample path as argument and returns True if model needs to be filtered out\n",
    "    'num_threads' : 8,\n",
    "    'shuffle_path' : True,\n",
    "    'verbosity' : 3,\n",
    "    'getitem' : \"tokens+props\",\n",
    "    'ignore_bn' : False,\n",
    "    'tokensize' : tokensize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a9a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:dataset splits are unintelligble. Load 100% of dataset\n",
      "2023-08-17 11:17:52,813\tWARNING services.py:1780 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1073729536 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=2.50gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-08-17 11:17:52,880\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 65.48it/s]\n",
      "718it [01:43, 13.28it/s]"
     ]
    }
   ],
   "source": [
    "#trainset = DatasetTokens(root=[zoo_path.absolute()], train_val_test='train',  property_keys=property_keys, **dataset_config)\n",
    "testset = DatasetTokens(root=[zoo_path.absolute()], train_val_test='test',  property_keys=property_keys, **dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.__get_paths__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46ba786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0136,  0.0125,  0.0753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0114,  0.0386, -0.0020,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0549, -0.0086, -0.0125,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0779,  0.0552, -0.1352,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0302,  0.0685,  0.0684,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0154,  0.0507, -0.0480,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]]),\n",
       " tensor([[ 0,  0,  0],\n",
       "         [ 1,  0,  1],\n",
       "         [ 2,  0,  2],\n",
       "         [ 3,  0,  3],\n",
       "         [ 4,  0,  4],\n",
       "         [ 5,  0,  5],\n",
       "         [ 6,  0,  6],\n",
       "         [ 7,  0,  7],\n",
       "         [ 8,  1,  0],\n",
       "         [ 9,  1,  1],\n",
       "         [10,  1,  2],\n",
       "         [11,  1,  3],\n",
       "         [12,  1,  4],\n",
       "         [13,  1,  5],\n",
       "         [14,  2,  0],\n",
       "         [15,  2,  1],\n",
       "         [16,  2,  2],\n",
       "         [17,  2,  3],\n",
       "         [18,  3,  0],\n",
       "         [19,  3,  1],\n",
       "         [20,  3,  2],\n",
       "         [21,  3,  3],\n",
       "         [22,  3,  4],\n",
       "         [23,  3,  5],\n",
       "         [24,  3,  6],\n",
       "         [25,  3,  7],\n",
       "         [26,  3,  8],\n",
       "         [27,  3,  9],\n",
       "         [28,  3, 10],\n",
       "         [29,  3, 11],\n",
       "         [30,  3, 12],\n",
       "         [31,  3, 13],\n",
       "         [32,  3, 14],\n",
       "         [33,  3, 15],\n",
       "         [34,  3, 16],\n",
       "         [35,  3, 17],\n",
       "         [36,  3, 18],\n",
       "         [37,  3, 19],\n",
       "         [38,  4,  0],\n",
       "         [39,  4,  1],\n",
       "         [40,  4,  2],\n",
       "         [41,  4,  3],\n",
       "         [42,  4,  4],\n",
       "         [43,  4,  5],\n",
       "         [44,  4,  6],\n",
       "         [45,  4,  7],\n",
       "         [46,  4,  8],\n",
       "         [47,  4,  9]], dtype=torch.int32),\n",
       " tensor([ 0.9080, 50.0000]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0b0bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_acc', 'training_iteration'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.properties.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e840670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa75c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ersion": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
